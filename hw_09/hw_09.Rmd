---
title: "Tenth Week: Principal Component Analysis and Factor Analysis"
subtitle: "PCA Stock, image, ..."
author: "Mina Moosavi - 93106788"
date: "`r Sys.time()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

<div align="center">
<img  src="images/stock.jpg"  align = 'center'>
</div>

> <p dir="RTL"> 
با استفاده از داده های OHLCV شرکت های تشکیل دهنده شاخص s&p500 و همچنین داده مربوط به شاخص های اقتصادی به سوالات زیر پاسخ دهید.
</p>

***
<p dir="RTL">
بارگزاری داده ها و کتابخانه ها:
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(highcharter)

name = list.files("data/stock_dfs/") %>% str_replace(".csv", "")
textpath = list.files("data/stock_dfs/", full.names = T)

.data <- read_csv(textpath[1]) %>% select(Date, Open, Close, Volume)
.data$stock_name = name[1]
sp500 = .data

for( i in 2:length(name)){
  .data <- read_csv(textpath[i]) %>% select(Date, Open, Close, Volume)
  .data$stock_name = name[i]
  sp500 = bind_rows(sp500, .data)
}

sp500 <- sp500 %>% mutate(
                 Year = as.numeric(format(Date, format = "%Y")),
                 Month = as.numeric(format(Date, format = "%m")),
                 Day = as.numeric(format(Date, format = "%d")),
                 Open = as.numeric(Open), 
                 Close = as.numeric(Close), 
                 Volume = as.numeric(Volume))

indexes <- read_csv("data/indexes.csv")

sector <- read_csv("data/constituents.csv")
```

<p dir="RTL">
برای ادغام داده های شرکت های مختلف در یک فایل، آن ها را به صورت افقی به یکدیگر اضافه می کنیم و معیار نام شرکت به داده ها اضافه می کنیم. در نهایت نیز تاریخ را به معیارهای آن تجزیه می کنیم.
</p>

***

<p dir="RTL">
۱. چه شرکتی رکورددار کسب بیشترین سود در بازه یکساله، دو ساله و پنج ساله می باشد؟ این سوال را برای بخش های مختلف مورد مطالعه قرار دهید و رکورددار را معرفی کنید. (برای این کار به ستون sector داده constituents مراجعه کنید.) برای هر دو قسمت نمودار سود ده شرکت و یا بخش برتر را رسم نمایید.
</p>

<p dir="RTL">
برای این سوال، درصد سود را به صورت سالیانه و دوساله و پنج ساله حساب می کنیم و بیشترین درصد سود را نمایش می دهیم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
sp500 <- sp500 %>% inner_join(sector, by = c("stock_name" = "Symbol"))

# Annual
stock_yearly <- full_join(
  sp500 %>% group_by(stock_name, Year) %>% arrange(Month, Day) %>% slice(1) %>% summarise(Start = Close, Sector = Sector),
  sp500 %>% group_by(stock_name, Year) %>% arrange(-Month, -Day) %>% slice(1) %>% summarise(End = Close, Sector = Sector),
  by = c("stock_name", "Year", "Sector")
) %>% select(Year, stock_name, Start, End, Sector)

stock_yearly <- stock_yearly %>% mutate(profit = 100*((End - Start)/Start)) %>% ungroup()
```

<p dir="RTL">
بیشتر سود در یک سال)
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
knitr::kable(stock_yearly %>% arrange(desc(profit)) %>% slice(1))
```

<p dir="RTL">
بیشترین سود سالانه در هر بخش)
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
knitr::kable(stock_yearly %>% group_by(Sector) %>% arrange(desc(profit)) %>% slice(1))

stock_yearly %>% group_by(Sector) %>% arrange(desc(profit)) %>% slice(1) %>% 
  hchart(type = "column", hcaes(x = stock_name, y = profit, group = Sector)) %>% 
  hc_yAxis(title = list(text = "Profit Percentage")) %>% 
  hc_xAxis(type = 'category', title = list(categories = stock_yearly$stock_name, text = "Stock Name")) %>% 
  hc_title(text = "Top Annual Profitable Stocks", style = list(fontWeight = "bold")) %>% 
  hc_add_theme(hc_theme_flat())
```

```{r, message=FALSE, warning=FALSE, comment=NA}
# Every Two Year
stock_yearly$two_year_profit = 0

for (i in name) {
  stock = stock_yearly %>% filter(stock_name == i)
  for (j in 1:nrow(stock)) {
    if (j != 1) {
      # profit for other years!
      stock_yearly[stock_yearly$stock_name == i & stock_yearly$Year == stock[j,]$Year,]$two_year_profit = 100*((stock[j,]$End - stock[j - 1,]$Start)/stock[j - 1,]$Start)
    }
  }
}
```

<p dir="RTL">
بیشترین سود در بازه ی دو ساله)
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
knitr::kable(stock_yearly %>% arrange(desc(two_year_profit)) %>% slice(1))
```

<p dir="RTL">
بیشترین سود در هر بخش در بازه ی دو ساله)
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
knitr::kable(stock_yearly %>% group_by(Sector) %>% arrange(desc(two_year_profit)) %>% slice(1))

stock_yearly %>% group_by(Sector) %>% arrange(desc(two_year_profit)) %>% slice(1) %>% 
  hchart(type = "column", hcaes(x = stock_name, y = two_year_profit, group = Sector)) %>% 
  hc_yAxis(title = list(text = "Profit Percentage")) %>% 
  hc_xAxis(type = 'category', title = list(categories = stock_yearly$stock_name, text = "Stock Name")) %>% 
  hc_title(text = "Top Two Year Profitable Stocks", style = list(fontWeight = "bold")) %>% 
  hc_add_theme(hc_theme_538())
```

```{r, message=FALSE, warning=FALSE, comment=NA}
# Every Five Year
stock_yearly$five_year_profit = 0

for (i in name) {
  stock = stock_yearly %>% filter(stock_name == i)
  for (j in 1:nrow(stock)) {
    if (j > 4) {
      # profit for other years!
      stock_yearly[stock_yearly$stock_name == i & stock_yearly$Year == stock[j,]$Year,]$five_year_profit = 100*((stock[j,]$End - stock[j - 4,]$Start)/stock[j - 4,]$Start)
    }
  }
}
```

<p dir="RTL">
بیشترین سود در بازه ی پنج ساله)
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
knitr::kable(stock_yearly %>% arrange(desc(five_year_profit)) %>% slice(1))
```

<p dir="RTL">
بیشترین سود در هر بخش در بازه ی پنج ساله)
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
knitr::kable(stock_yearly %>% group_by(Sector) %>% arrange(desc(five_year_profit)) %>% slice(1))

stock_yearly %>% group_by(Sector) %>% arrange(desc(five_year_profit)) %>% slice(1) %>% 
  hchart(type = "column", hcaes(x = stock_name, y = five_year_profit, group = Sector)) %>% 
  hc_yAxis(title = list(text = "Profit Percentage")) %>% 
  hc_xAxis(type = 'category', title = list(categories = stock_yearly$stock_name, text = "Stock Name")) %>% 
  hc_title(text = "Top Five Year Profitable Stocks", style = list(fontWeight = "bold")) %>% 
  hc_add_theme(hc_theme_elementary())
```

***

<p dir="RTL">
۲. یک اعتقاد خرافی می گوید خرید سهام در روز سیزدهم ماه زیان آور است. این گزاره را مورد ارزیابی قرار دهید.
</p>

<p dir="RTL">
برای تست این موضوع، ابتدا میزان سود را به ازای تمامی شرکت ها در تمامی روزها حساب می کنیم. سپس برای هر روز نرخی به نام شکست تعریف می کنیم که برابر با نسبت تعداد شرکت های دارای افت سهام به تعداد کلی شرکت ها است. در نهایت روز ۱۳ ام ماه را از سایر روزها جدا می کنیم و بین این دو گروه آزمون فرض انجام می دهیم. در این آزمون فرض صفر را برابر بودن نرخ شکست در ۱۳ ام ماه و سایر روزها در نظر میگیریم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
sp500 <- sp500 %>% mutate(profit = 100*((Close - Open)/Open))

non_profit_range <- sp500 %>% filter(profit < 0) %>% group_by(Year, Month, Day) %>% summarise(damage_rate = n()/505)

thirteen <- non_profit_range %>% filter(Day == 13)
non_thirteen <- non_profit_range %>% filter(Day != 13)

t.test(thirteen$damage_rate, non_thirteen$damage_rate, alt = "two.sided")

```

<p dir="RTL">
همانطور که نتیجه ی بالا نشان می دهد، فرض یکسان بودن عملکرد در سیزدهم ماه با سایر روزها رد نمی شود، پس نمی توانیم فرض خرافی را قبول کنیم.
</p>

***

<p dir="RTL">
۳. رکورد بیشترین گردش مالی در تاریخ بورس برای چه روزی بوده است و چرا!!!
</p>

<p dir="RTL">
معیار گردش مالی را مجموع تعداد سهام مبادله شده ی تمامی شرکت ها در نظر میگیریم. در این صورت خروجی به شکل زیر می شود:
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
max_flow <- sp500 %>%
  group_by(Date) %>% 
  summarise(flow = sum(Volume)) %>% 
  arrange(desc(flow)) %>% slice(1:4)

knitr::kable(max_flow)
```

<p dir="RTL">
همانطور که مشاهده می کنیم، بیشترین معامله در روز ۸ اکتبر سال ۲۰۰۸ بوده است که این روز در دوران [رکود اقتصادی آمریکا](https://en.wikipedia.org/wiki/Stock_market_crash#Crash_of_2008%E2%80%932009)
قرار دارد. علت رخداد این رکود از بین رفتن حباب ۸ تریلیون دلاری مسکن بود که با عواملی همچون [مشکلات بانکی](https://www.thebalance.com/subprime-mortgage-crisis-effect-and-timeline-3305745)
و رد لایحه کمک بانکی از طرف کنگره تشدید شد.
<br>
البته همانطور که مشاهده می کنیم، بیشترین سقوط پس از آن نیز در تاریخ ۸ آگوست سال ۲۰۱۱ بوده است. علت وقوع این سقوط نیز این بود که 
s&p
میزان اعتبار بازار آمریکا را از 
AAA 
به 
AA+
تنزل داد.
</p>

***

<p dir="RTL">
۴. شاخص AAPL که نماد شرکت اپل است را در نظر بگیرید. با استفاده از رگرسیون خطی یک پیش کننده قیمت شروع (open price) بر اساس k روز قبل بسازید. بهترین انتخاب برای k چه مقداری است؟ دقت پیش بینی شما چقدر است؟
</p>

<p dir="RTL">
برای حل این سوال، ستون های روزهای قبل را به داده ها اضافه می کنیم و مدل های مختلفی با تعداد روزهای مختلفی لرن کرده و دقت آن را بوسیله
r.squared 
بدست می آوریم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
appl <- sp500 %>% filter(stock_name == "AAPL") %>% arrange(desc(Date)) %>% 
  select(-stock_name, -Name, -Sector, -Volume, -Close)


# k = 1
appl$k1 = c(appl[-c(1),]$Open, 0)
lm = lm(data = appl, formula = Open~k1)
ans <- data.frame(1, summary(lm)$r.squared)
names(ans)<-c("k","R Squared")

# k = 2
appl$k2 = c(appl[-c(1,2),]$Open, 0,0)
lm = lm(data = appl, formula = Open~k1+k2)
ans_1 <- data.frame(2, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 3
appl$k3 = c(appl[-c(1,2,3),]$Open, 0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3)
ans_1 <- data.frame(3, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 4
appl$k4 = c(appl[-c(1,2,3,4),]$Open, 0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4)
ans_1 <- data.frame(4, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 5
appl$k5 = c(appl[-c(1,2,3,4,5),]$Open, 0,0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4+k5)
ans_1 <- data.frame(5, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 6
appl$k6 = c(appl[-c(1,2,3,4,5,6),]$Open, 0,0,0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4+k5+k6)
ans_1 <- data.frame(6, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 7
appl$k7 = c(appl[-c(1,2,3,4,5,6,7),]$Open, 0,0,0,0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4+k5+k6+k7)
ans_1 <- data.frame(7, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 8
appl$k8 = c(appl[-c(1,2,3,4,5,6,7,8),]$Open, 0,0,0,0,0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4+k5+k6+k7+k8)
ans_1 <- data.frame(8, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 9
appl$k9 = c(appl[-c(1,2,3,4,5,6,7,8,9),]$Open, 0,0,0,0,0,0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4+k5+k6+k7+k8+k9)
ans_1 <- data.frame(9, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 10
appl$k10 = c(appl[-c(1,2,3,4,5,6,7,8,9,10),]$Open, 0,0,0,0,0,0,0,0,0,0)
lm = lm(data = appl, formula = Open~k1+k2+k3+k4+k5+k6+k7+k8+k9+k10)
ans_1 <- data.frame(10, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

knitr::kable(ans)
```

<p dir="RTL">
همانطور که در بالا مشاهده می کنیم، هر چه تعداد روز بیشتری را به مدل اضافه می کنیم، دقت مدل بیشتر می شود.
</p>

***

<p dir="RTL">
۵. بر روی داده های قیمت شروع شرکت ها الگوریتم pca را اعمال کنید. نمودار تجمعی درصد واریانس بیان شده در مولفه ها را رسم کنید. سه مولفه اول چند درصد از واریانس را تبیین می کند؟
</p>

<p dir="RTL">
از آنجایی که به منظور راحتی تحلیل مکاشفه ای، داده ها را به صورت ردیفی اضافه کرده بودیم، ابتدا برای این سوال داده را به شکل مناسب در آورده و سپس 
pca 
را اعمال می کنیم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
# data preparation
.data <- read_csv(textpath[1]) %>% select(Date, Open)
colnames(.data) = c("Date", name[1])
sp500_pca = .data

for(i in 2:length(name)){
  .data <- read_csv(textpath[i]) %>% select(Date, Open)
  colnames(.data) = c("Date", name[i])
  sp500_pca = merge(sp500_pca, .data)
}

# pca
stock_pca = prcomp(sp500_pca %>% select(-Date), scale. = TRUE)

plot(summary(stock_pca)$importance[3,], type="l",
     ylab="% variance explained", xlab="nth component (decreasing order)") + 
  abline(h=0.98,col="red");abline(v = 25,col="red",lty=3)

sum((stock_pca$sdev^2)[1:3])/sum((stock_pca$sdev^2))
```

***

<p dir="RTL">
۶. برای هر نماد اطلاعات بخش مربوطه را از داده constituents استخراج نمایید. برای هر بخش میانگین روزانه قیمت شروع شرکت های آن را محاسبه کنید. سپس با استفاده از میانگین به دست آمده  داده ایی با چند ستون که هر ستون یک بخش و هر سطر یک روز هست بسازید. داده مربوط را با داده شاخص های اقتصادی ادغام کنید. بر روی این داده pca بزنید و نمودار biplot آن را تفسیر کنید.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
# data preparation
sector_value <- sp500 %>% group_by(Date, Sector) %>% summarise(Open = mean(Open)) %>% ungroup()

sector_names <- sector %>% ungroup() %>% select(Sector) %>% distinct()

.data = sector_value %>% filter(Sector == sector_names[[1]][1]) %>% select(-Sector)
colnames(.data) = c("Date", sector_names[[1]][1])
sector_pca = .data

for(i in 2:nrow(sector_names)){
  .data = sector_value %>% filter(Sector == sector_names[[1]][i]) %>% select(-Sector)
  colnames(.data) = c("Date", sector_names[[1]][i])
  sector_pca = merge(sector_pca, .data, by = "Date")
}
sector_pca = sector_pca %>% merge(indexes, by = "Date") %>% select(-Date)

# pca
sector_stock_pca = prcomp(sector_pca, scale. = TRUE)
biplot(sector_stock_pca, scale = 1, pc.biplot = TRUE)

library(ggbiplot)
ggbiplot(sector_stock_pca, obs.scale = 1, var.scale = 1,
         ellipse = TRUE, circle = TRUE) +
  scale_color_discrete(name = '') +
  theme(legend.direction = 'horizontal', legend.position = 'top')
```

<p dir="RTL">
همانطور که در نمودارهای بالا مشاهده می کنیم، بخش های مختلف بورس در
PC1 
موثر هستند و همگی پترن پاسخدهی مشابه دارند. همچنین برای
PC2 
متغیر 
PE10 
بیشترین تاثیر را دارد. هم چنین مشاهده می کنیم که الگوی پاسخدهی 
Consumer Price Index 
کاملا مخالف 
Long Interest Rate 
است.
</p>

***

<p dir="RTL">
۷. روی همه اطلاعات (OHLCV) سهام اپل الگوریتم PCA را اعمال کنید. سپس از مولفه اول برای پیش بینی قیمت شروع سهام در روز آینده استفاده کنید. به سوالات سوال ۴ پاسخ دهید. آیا استفاده از مولفه اول نتیجه بهتری نسبت به داده open price برای پیش بینی قیمت دارد؟
</p>

<p dir="RTL">
برای حل سوال ابتدا داده ی 
AAPL 
را خوانده و سپس برای آن 
pca 
را محاسبه می کنیم و در نهایت مولفه ی اول 
pca 
را به داده ی سوال چهار به صورت ستونی(با یک ترتیب) اضافه می کنیم. در پایان مراحل سوال چهار را محاسبه می کنیم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
appl_ohlcv <- read_csv("data/stock_dfs/AAPL.csv") %>% arrange(Date) %>% select(-Date)
appl <- appl %>% arrange(Date)

appl_pca = prcomp(appl_ohlcv, scale. = TRUE)
appl_pca1 = appl_pca$x %>% as.data.frame() %>% select(PC1)

appl$pca = appl_pca1$PC1

# k = 1
lm = lm(data = appl, formula = pca~k1)
ans <- data.frame(1, summary(lm)$r.squared)
names(ans)<-c("k","R Squared")

# k = 2
lm = lm(data = appl, formula = pca~k1+k2)
ans_1 <- data.frame(2, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 3
lm = lm(data = appl, formula = pca~k1+k2+k3)
ans_1 <- data.frame(3, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 4
lm = lm(data = appl, formula = pca~k1+k2+k3+k4)
ans_1 <- data.frame(4, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 5
lm = lm(data = appl, formula = pca~k1+k2+k3+k4+k5)
ans_1 <- data.frame(5, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 6
lm = lm(data = appl, formula = pca~k1+k2+k3+k4+k5+k6)
ans_1 <- data.frame(6, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 7
lm = lm(data = appl, formula = pca~k1+k2+k3+k4+k5+k6+k7)
ans_1 <- data.frame(7, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 8
lm = lm(data = appl, formula = pca~k1+k2+k3+k4+k5+k6+k7+k8)
ans_1 <- data.frame(8, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 9
lm = lm(data = appl, formula = pca~k1+k2+k3+k4+k5+k6+k7+k8+k9)
ans_1 <- data.frame(9, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

# k = 10
lm = lm(data = appl, formula = pca~k1+k2+k3+k4+k5+k6+k7+k8+k9+k10)
ans_1 <- data.frame(10, summary(lm)$r.squared)
names(ans_1)<-c("k","R Squared")
ans <- ans %>% rbind(ans_1)

knitr::kable(ans)
```

<p dir="RTL">
همانطور که مشاهده می کنیم، دقت ما نسبت به سوال ۴ یک درصد کاهش یافته است. پس مولفه ی اول 
pca 
نسبت به 
open price 
نتیجه ی بهتری نمی دهد.
</p>

***

<p dir="RTL">
۸. نمودار سود نسبی شاخص s&p500 را رسم کنید. آیا توزیع سود نرمال است؟(از داده indexes استفاده کنید.)
با استفاده از ده مولفه اول سوال پنج آیا می توانید سود و ضرر شاخص s&p500 را برای روز آينده پیش بینی کنید؟ از یک مدل رگرسیون لاجستیک استفاده کنید. درصد خطای پیش بینی را به دست آورید.
</p>

<p dir="RTL">
برای حل این سوال، سود نسبی را برابر با نسبت اختلاف
sp500
امروز و روز قبل به 
sp500 
روز قبل میگیریم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
indexes <- indexes %>% mutate(profit = 100*(SP500 - lag(SP500))/lag(SP500))

indexes %>% 
  ggplot(aes(profit, fill=..count..)) + geom_histogram(binwidth = 1) +
  scale_fill_gradient(low="darkgreen", high="gold") + 
  ggtitle("SP500 Profit Distribution")
```

<p dir="RTL">
همانطور که در نمودار می بینیم، سود نسبی شاخص
SP500 
حول صفر توزیع نرمال دارد.
</p>

<p dir="RTL">
برای حل ادامه ی سوال، متغیری به نام سودوزیان تعریف می کنیم که در صورتی که سود نسبی بیشتر از صفر بود آن را ۱ (به معنی سود) و در غیر این صورت آن را صفر(به معنی ضرر ) می گذاریم. سپس از داده های سوال ۵ ده مولفه ی اول 
pca 
را انتخاب کرده و آن را با داده ها مرج می کنیم. در نهایت نیز با کمک
glm 
و خانواده ی 
binomial
مدل را لرن می کنیم.
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
indexes <- indexes %>% mutate(loss_gain = ifelse(profit > 0, 1, 0))

pcas <- stock_pca$x %>% as.data.frame() %>% select(PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10)

# indexes_pca <- sp500_pca %>% merge(pcas) %>% merge(indexes %>% merge(sp500_pca))
indexes_pca <- indexes %>% merge(sp500_pca, by = "Date") %>% merge(pcas)

glm = glm(data = indexes_pca, formula = loss_gain ~ PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10, family = binomial(link = 'logit'))
summary(glm)

indexes_pca$prediction  = predict(glm, newdata = indexes_pca, type = "response")
indexes_pca <- indexes_pca %>% mutate(get = ifelse(prediction < 0.5, 0, 1))
P <- indexes_pca %>% filter(loss_gain == 1) %>% nrow()
N <- indexes_pca %>% filter(loss_gain == 0) %>% nrow()
TP <- indexes_pca %>% filter(loss_gain == 1 & get == 1) %>% nrow()
TN <- indexes_pca %>% filter(loss_gain == 0 & get == 0) %>% nrow()
ACC <- (TP + TN)/(P + N)
cat("Accuracy: ", ACC)
```

<p dir="RTL">
همانطور که خروجی 
glm
نشان می دهد، هیچ کدام از مولفه های 
pca 
تاثیری در پیشبینی سود و زیان ندارد. البته باید دقت داشته باشیم که مشکل اصلی این سوال داده های آن است که در 
PCA 
تنها ۱۲۶ داده باقی می ماند که در نتیجه ی مرج با سوال پنج داده ی بسیار کمی باقی می ماند. اما مشاهده می کنیم که با این وجود، دقت مدل ما ۷۵ درصد است.
</p>

***

<p dir="RTL"> 
۹. عکسی که در ابتدای متن آمده را در نظر بگیرید. با استفاده از pca عکس را فشرده کنید. سپس نمودار حجم عکس فشرده بر حسب تعداد مولفه اصلی را  رسم کنید. بهترین انتخاب برای انتخاب تعداد مولفه ها در جهت فشرده سازی چه عددی است؟
</p>

```{r, message=FALSE, warning=FALSE, comment=NA}
library("EBImage")

pic = flip(readImage("images/stock.jpg"))
red_data <- imageData(pic)[,,1]
green_data <- imageData(pic)[,,2]
blue_data <- imageData(pic)[,,3]

# red component
pca.img_red = prcomp(red_data, scale=TRUE)
plot(summary(pca.img_red)$importance[3,], type="l",
     ylab="%variance explained", xlab="nth component (decreasing order)", main = "Red Component") + 
  abline(h=0.99,col="red");abline(v = 89,col="red",lty=3)
# to capture 99% of the variance, we need the first 89 components
sum((pca.img_red$sdev^2)[1:89])/sum((pca.img_red$sdev^2))
chosen.components = 1:89
feature.vector_red = pca.img_red$rotation[,chosen.components]
compact.data_red = t(feature.vector_red) %*% t(red_data)
approx.img_red = t(feature.vector_red %*% compact.data_red)
pic[ , , 1] = approx.img_red

# green component
pca.img_green = prcomp(green_data, scale=TRUE)
plot(summary(pca.img_green)$importance[3,], type="l",
     ylab="%variance explained", xlab="nth component (decreasing order)", main = "Green Component") + 
  abline(h=0.99,col="red");abline(v = 114,col="red",lty=3)
# to capture 99% of the variance, we need the first 114 components
sum((pca.img_green$sdev^2)[1:114])/sum((pca.img_green$sdev^2))
chosen.components = 1:114
feature.vector_green = pca.img_green$rotation[,chosen.components]
compact.data_green = t(feature.vector_green) %*% t(green_data)
approx.img_green = t(feature.vector_green %*% compact.data_green)
pic[ , , 2] = approx.img_green

# blue component
pca.img_blue = prcomp(blue_data, scale=TRUE)
plot(summary(pca.img_blue)$importance[3,], type="l",
     ylab="%variance explained", xlab="nth component (decreasing order)", main = "Blue Component") + 
  abline(h=0.99,col="red");abline(v = 120,col="red",lty=3)
# to capture 99% of the variance, we need the first 120 components
sum((pca.img_blue$sdev^2)[1:120])/sum((pca.img_blue$sdev^2))
chosen.components = 1:120
feature.vector_blue = pca.img_blue$rotation[,chosen.components]
compact.data_blue = t(feature.vector_blue) %*% t(blue_data)
approx.img_blue = t(feature.vector_blue %*% compact.data_blue)
pic[ , , 3] = approx.img_blue

plot(flip(pic))

```

<p dir="RTL">
برای این سوال 
pca 
را برای هر سه رنگ قرمز و سبز و آبی اعمال می کنیم که برای قرمز ۸۹ مولفه، برای سبز ۱۱۴ مولفه و برای آبی ۱۲۰ مولفه به ما پوشش ۹۹ درصدی می دهد.
</p>

***

<p dir="RTL"> 
۱۰. پنج ایده جالبی که روی داده های مالی بالا می توانستیم پیاده کنیم را بیان کنید. (ایده کافی است نیازی به محاسبه بر روی داده نیست.)
</p>

<p dir="RTL">
۱. نمایش روند سود و زیان بخش های مختلف بورس، یافتن پر سود ترین بخش
<br>
۲. بررسی میزان خسارت بخش های مختلف پس از رخدادهای بورس، یافتن کم خطرترین و پایدارترین بخش ها
<br>
۳. تحقیق این موضوع که خرید مقدار کمی از یک سهام پر ارزش سود ده تر است یا خرید مقدار بیشتر از یک سهام کم ارزش با رشد بالا
<br>
۴. نمایش نمودار موزایک حجم معاملات بخش های مختلف و پنج شرکت برتر هر بخش
<br>
۵. بدست آوردن مدل 
glm 
برای تحلیل فروش سهام در زمان ضرردهی
</p>

